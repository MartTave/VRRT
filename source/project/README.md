# VRRT

This folder contain the practical solution to the Video-based Realtime Race Timing problem.

This readme will describe the practical aspect of this folder, i.e. how to install the dependancies, how to launch the code, and the folder organisation

## Installation

This project use the [UV](https://docs.astral.sh/uv/) package manager. This means that all the project dependencies are listed in [pyproject.toml](./pyproject.toml).

Some packages are present on special repositories (paddlepaddle-gpu). The indexes url are listed in the corresponding section in the file. The package `open-cv-python-headless` is blacklisted, as we already have opencv installed, and we don't want the headless package to override the installed one.

The python version is `3.11`. It is pinned in the [.python-version](./.python-version) file.


## Folder structure

In the root of this folder is every script you can launch directly. This means that every .py files present here are scripts that can be run directly.

- `create_parameters.py` - This script is a helper to create the cropping region and the arrival line for a video
- `depth_precision_benchmark.py` - This script is used to generate a benchmark for the depth estimation solution
- `ocr_benchmark.py` - This script is used to generate a benchmark for the OCR solution
- `main.py` - This is the main script of the folder. It is an example of how to use the entire VRRT solution
- `output_analyzer.py` - This is a script to analyze and compare the output generated by the `main.py` script
- `parse_race_results.py` - This is a script to parse the race results from CSV to json and convert the timestamp to a python friendly one

### ./classes
- `bib_detector.py` - This file contains the abstract classe and an example implementation of it for the bib detection
- `bib_reader.py` - This file contains the abstract classe and an example implementation of it for the bib reading
- `depth.py` - This file contains all the logic for the detection of person passing the arrival line
- `detectors.py` - This files contains an example of a manual tracker implementation. It is not currently used in the solutions, but it can be if needed
- `person_detector.py` - This file contains the abstract classe and an example implementation of it for the person detection
- `pipeline.py` - This file contains the code responsible for the integration of all the above
- `tools.py` - This file contains helper functions


## Usage

To use the solution two things are needed :

- The two points defining the croppping region
- The two points defining the arrival line

To create those, you can run `uv run create_parameters.json`. In this file, you can choose the source from the frame on which to pick the cropping region and the arrival line. You can choose between a video file (and a specific frame from it), a image file, or a webcam directy.

Once the parameter file has been createdm you can then either run the `main.py` file, which contain an example of usage of the pipeline class, or you can create you own file based on it !
